線性回歸（Linear Regression）是一種用來建立和預測數值型結果的統計模型。它假設自變數（特徵）和因變數之間存在線性關係。

簡單線性回歸處理一個自變數和一個因變數，表達形式為：

\[ y = mx + b \]

其中：
- \(y\) 是因變數（要預測的目標），
- \(x\) 是自變數（特徵），
- \(m\) 是斜率，
- \(b\) 是截距。

多變數線性回歸處理多個自變數和一個因變數，表達形式為：

\[ y = b_0 + b_1x_1 + b_2x_2 + \ldots + b_nx_n \]

其中：
- \(y\) 是因變數，
- \(x_1, x_2, \ldots, x_n\) 是多個自變數，
- \(b_0\) 是截距，
- \(b_1, b_2, \ldots, b_n\) 是各自變數的係數。

線性回歸的目標是找到最佳的係數 \(m\) 和 \(b\) 或 \(b_0, b_1, \ldots, b_n\)，使得模型的預測值和實際值的誤差最小化。這個過程通常使用最小二乘法（Least Squares Method）來進行。

線性回歸在實際應用中常被用於預測或建模，特別是在探索特徵和目標之間的關係時。
